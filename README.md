# Machine Learning Model

## Preliminary Preparation

The data for this project was taken off of Kaggle.com and contains information for over 2 million flights in the United States. This data was used to try and understand what factors can contribute to a flight being delayed or cancelled. In order to make this data usuable for machine learning model, all of the null values were removed and unnecessary columns were dropped. All of the originating flights by their location were examined and there was a large discrepancy in the numbers so the origination locations with less than 100,000 flights were grouped into an "other" column. The originated locations were then one-hot encoded. The destination locations were also slimmed down into an "other" column if they had less than 100,000 flights. The destination location columns were also one-hot encoded. All of the carrier codes were one-hot encoded as well as the cancellation codes. Columns with unique information such as flight_id and mkt_carrier_fl_num were removed since they would not be beneficial to the model.

### Feature Selection

For this project, all of the data was labeled with outcomes and there was already a column with binary values for if a flight was delayed or not ('dep_del15'). This column provides the opportunity to run a classification model such as a logistic regression or random forest model and all of the other cleaned and encoded columns could be used to provide factors to decide of a flight will be delayed or not. Some of the variables used to determine if a flight is delayed will be the origin of the flight, the airline, the date and the time of departure. There was also a binary column for if a flight was cancelled ('cancelled') or not which allows another analysis on cancelled flights with the same information.

## Training and Testing Split

The data for this model was split using the train_test_split function from the sklearn.model_selection library. Since there is a lot of data in this dataset the data can be split into a 75% training set and a 25% testing set. There was a huge discrepancy between the number of on-time flights (2476064) and delayed flights (269783) meaning that a sampling method needed to be used to address the discrepancy. There was a similar problem for cancelled flights (282926) and non-cancelled flights (2462921). Naive Random Oversampling was choosen as a sampling method for both the cancelled and delayed models.

## Model Choice

Since all of the data is labeled with outcomes of each flight, a supervised machine learning model would be appropiate for this project and since there is a binary outcome column with delayed flight information this data is already set up for a logistic regression model or a random forest model. A logistic regression model was choosen because it is a fairly simple model that is easy to implement and gives a clear outcome. It might not produce a good outcome since there are so many features beings used for this analysis. A random forest classifier model will be used in the case that the logistic regression model is not adequate. A random forest model is beneficial since it can take a lot of input features, can handle a large dataset more efficiently than other models and reduces the chance of overfitting. One disadvantage is that a random forest model is harder to interpret and relies on feature importance to explain it.

### Testing the Model

It took a good amount of time to clean the entire dataset and figure out a way to store the dataset in AWS and merge the appropiate tables in SQL. The final dataset was successfully loaded and separated into training and testing sets and scaled. There were two completely different models run on the delayed flights and the cancelled flights. Naive random oversampling was chosen as the method for the logistic regression model due to time constraints.

#### Delayed Flights

- The delayed flights model was trained using naive random oversampling to address the difference in sample numbers and then put into a logistic regression model, the accuracy was a little over 62% (0.623469) and a confusion matrix and an imbalanced classification report were generated with the output below. ![Accuracy of Logistic Regression for Delays](https://github.com/lmacera/Winning_Winers/blob/likenberry_branch/Resources/Accuracy_lm_delay.png)![Confusion Matrix of LR for Delays](https://github.com/lmacera/Winning_Winers/blob/likenberry_branch/Resources/Matrix_lm_delay.png) The confusion matrix showed that this model did have more true positives and true negatives than false positives and false negatives but there could be some improvement. ![Classification Report of LR for Delays](https://github.com/lmacera/Winning_Winers/blob/likenberry_branch/Resources/Class_report_lm_delay.png) The imbalanced classification report showed that this model was much better at predicting on-time flights than delayed flights with a precision score of 87% and a recall score of 67% meaning that a delayed flight was correctly classifed 67% of the time.

- Since the logistic regression model was not very successful at classifying delayed flights, a random forest classifier model was used and trained. The accuracy improved from 62% to 66% (0.667811) which is better than it was. ![Accuracy of RF for Delays](https://github.com/lmacera/Winning_Winers/blob/likenberry_branch/Resources/Accuracy_rf_delay.png) ![Confusion Matrix of RF for Delays](https://github.com/lmacera/Winning_Winers/blob/likenberry_branch/Resources/Matrix_rf_delay.png) showed that this model was little better at classifying true values than the false values. ![Classification Report of RF for Delays](https://github.com/lmacera/Winning_Winers/blob/likenberry_branch/Resources/Classreport_rf_delay.png) The classification report had very similar recall and precision scores to the logistic regression model. ![Top Features of RF for Delays](https://github.com/lmacera/Winning_Winers/blob/likenberry_branch/Resources/Top_feats_rf_delay.png) One of the features from the random forest model is a ranking of the importance of features to that model. This image shows the most important features which should be analyzed further to understand better what they mean.

#### Cancelled Flights

- Just as with the delayed flights, the cancelled flights were tested with a logistic regression model after naive over sampling the data. The accuracy for this model was about 72% (0.721583) which is better meaning that the model could correctly identify if a flight was cancelled or not 72% of the time. ![Accuracy of LR for Cancels](https://github.com/lmacera/Winning_Winers/blob/likenberry_branch/Resources/Accuracy_lm_cancel.png) ![Confusion Matrix of LR for Cancels](https://github.com/lmacera/Winning_Winers/blob/likenberry_branch/Resources/Matrix_lm_cancel.png) The confusion matrix showed that there were more true negatives and positives than false negatives and positives. ![Classification Report of LR for Cancels](https://github.com/lmacera/Winning_Winers/blob/likenberry_branch/Resources/Classreport_lm_cancel.png) The recall score for this model was surprisingly low at almost 69% but the precision score show that the model was better at predicting if a flight would be on time than if it was cancelled.
- After the logistic model did not return a very reliable model so a random forest model was run on the cancelled data. The accuracy of this model was almost 90% (0.899691) ![Accuracy of RF for Cancels](https://github.com/lmacera/Winning_Winers/blob/likenberry_branch/Resources/Accuracy_rf_cancel.png) This is a very good accuracy meaning this model is good at predicting on-time vs cancelled flights. ![Confusion Matrix of RF for Cancels](https://github.com/lmacera/Winning_Winers/blob/likenberry_branch/Resources/Matrix_rf_cancel.png) Here it is easy to see that almost all of the flights were correctly identified and labeled correctly. ![Classification Report of RF for Cancels](https://github.com/lmacera/Winning_Winers/blob/likenberry_branch/Resources/Classreport_rf_cancel.png) The recall score for this model was 87% which means that a flight was identified as cancelled or on-time 87% of the time and a precision score of 93% which is very good. ![Top Features of RF for Cancels](https://github.com/lmacera/Winning_Winers/blob/likenberry_branch/Resources/Top_feats_rf_cancel.png) These are the top features ranked by importance for the random forest model. The top four features are the same as the ones from the delayed model but in a different order. Future analysis should be done on these features.

### Conclusion

Overall, the random forest classifier models were better able to classify the data correctly than logistic regression. It was also easier to classify cancelled flights than delayed flights. The best accuracy score was from the random forest model for both cancelled and delayed flights. It was easier to classify cancelled than delayed flights. Future analysis would include testing other sampling methods and model that might more accurately represent this data. It would also be good to test this model on flight data covering a couple of years and investigate the important features presented by the random forest model. Statistical analysis could be performed to see if there was actual statistical significance to the features and between the effects of before during COVID-19.
